Skip to content
Navigation Menu
Tee-David
realtors_practice

Type / to search
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Settings
Quick Test Scrape
Quick Test Scrape #8
Jobs
Run details
Workflow file for this run
.github/workflows/test-quick-scrape.yml at 848a0c8
name: Quick Test Scrape

on:
  workflow_dispatch:
    inputs:
      site:
        description: 'Site to test (default: cwlagos)'
        required: false
        default: 'cwlagos'
      pages:
        description: 'Max pages to scrape'
        required: false
        default: '3'

jobs:
  test-scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('requirements.txt') }}

      - name: Install dependencies
        run: |
          echo "Installing Python packages..."
          pip install --upgrade pip
          pip install -r requirements.txt
          echo "Done!"
      - name: Install Playwright browsers
        run: |
          echo "Installing Playwright browsers..."
          playwright install --with-deps chromium
          echo "Done!"
      - name: Install system dependencies
        run: |
          playwright install-deps
      - name: Check system resources (BEFORE)
        run: |
          echo "=== System Resources BEFORE Scraping ==="
          free -h
          df -h
          echo "========================================"
      - name: Enable test site
        run: |
          echo "Enabling site: ${{ github.event.inputs.site || 'cwlagos' }}"
          python scripts/enable_one_site.py ${{ github.event.inputs.site || 'cwlagos' }}
      - name: Run test scrape
        env:
          RP_HEADLESS: 1
          RP_PAGE_CAP: ${{ github.event.inputs.pages || '3' }}
          RP_NO_IMAGES: 1
          RP_GEOCODE: 0
          RP_DEBUG: 1
          RP_NO_AUTO_WATCHER: 1
        run: |
          echo "Starting scrape..."
          echo "Site: ${{ github.event.inputs.site || 'cwlagos' }}"
          echo "Max pages: ${{ github.event.inputs.pages || '3' }}"
          echo ""
          python main.py
          echo "Scrape complete!"
      - name: Process exports with watcher
        run: |
          echo "Processing scraped data..."
          python watcher.py --once
      - name: Upload to Firestore
        env:
          FIREBASE_CREDENTIALS: ${{ secrets.FIREBASE_CREDENTIALS }}
        run: |
          echo "========================================="
          echo "Uploading test data to Firestore..."
          echo "========================================="
          # Check if master workbook exists
          if [ ! -f "exports/cleaned/MASTER_CLEANED_WORKBOOK.xlsx" ]; then
            echo "⚠️ WARNING: Master workbook not found!"
            echo "Watcher may have failed. Skipping Firestore upload for this test."
            exit 0
          fi
          # Check if Firebase credentials secret is set
          if [ -z "$FIREBASE_CREDENTIALS" ]; then
            echo "⚠️ WARNING: FIREBASE_CREDENTIALS secret not set!"
            echo "Skipping Firestore upload. Set secret to enable uploads."
            exit 0
          fi
          # Create temporary credentials file
          echo "$FIREBASE_CREDENTIALS" > firebase-temp-credentials.json
          # Validate credentials file is valid JSON
          if ! python -c "import json; json.load(open('firebase-temp-credentials.json'))" 2>/dev/null; then
            echo "❌ ERROR: Invalid Firebase credentials JSON!"
            rm firebase-temp-credentials.json
            exit 0
          fi
          echo "✅ Firebase credentials validated"
          # Set environment variable
          export FIREBASE_SERVICE_ACCOUNT=firebase-temp-credentials.json
          # Run upload script with enterprise schema transformation
          echo "Running upload script with enterprise schema (9 categories, 85+ fields)..."
          if python scripts/upload_to_firestore.py --cleanup --max-age-days 30; then
            echo "✅ Firestore upload completed successfully!"
          else
            echo "⚠️ WARNING: Firestore upload encountered errors"
          fi
          # Clean up credentials
          rm firebase-temp-credentials.json
          echo "========================================="
          echo "Firestore upload step complete!"
          echo "========================================="
      - name: Check system resources (AFTER)
        if: always()
        run: |
          echo "=== System Resources AFTER Scraping ==="
          free -h
          df -h
          echo "========================================"
      - name: Check results
        if: always()
        run: |
          echo "=== Scrape Results ==="
          echo "Export files:"
          find exports/ -name "*.csv" -o -name "*.xlsx" 2>/dev/null || echo "No export files found"
          echo ""
          echo "Latest log entries:"
          tail -50 logs/scraper.log 2>/dev/null || echo "No log file found"
          echo "======================"
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-scrape-results
          path: |
            exports/
            logs/scraper.log
          retention-days: 7

      - name: Summary
        if: always()
        run: |
          echo "=== Test Scrape Summary ==="
          echo "Site: ${{ github.event.inputs.site || 'cwlagos' }}"
          echo "Pages: ${{ github.event.inputs.pages || '3' }}"
          echo "Status: ${{ job.status }}"
          # Count results
          TOTAL=$(find exports/ -name "*.csv" -exec wc -l {} \; 2>/dev/null | awk '{sum+=$1} END {print sum}' || echo "0")
          echo "Total records: $TOTAL"
          echo "=========================="
test: Enable NPC site for quick Firestore test scrape · Tee-David/realtors_practice@848a0c8