# Nigerian Real Estate Scraper

> Comprehensive web scraper for aggregating property listings from 50+ Nigerian real estate websites, with intelligent data cleaning and export consolidation.

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
pip install pyyaml beautifulsoup4 openpyxl playwright requests pandas

# 2. Install browser for Playwright
playwright install chromium

# 3. Configure sites (optional)
cp config.example.yaml config.yaml

# 4. Run scraper
python main.py

# 5. Process exports
python watcher.py --once
```

## ğŸ“ Project Structure

```
realtors_practice/
â”œâ”€â”€ main.py                    # Main scraper entry point
â”œâ”€â”€ watcher.py                # Export watcher service
â”œâ”€â”€ config.yaml               # Configuration file
â”œâ”€â”€ CLAUDE.md                 # AI assistant context
â”‚
â”œâ”€â”€ core/                     # Core modules
â”‚   â”œâ”€â”€ config_loader.py     # Configuration management
â”‚   â”œâ”€â”€ scraper_engine.py    # Generic scraping engine
â”‚   â”œâ”€â”€ dispatcher.py        # Parser dispatch system
â”‚   â”œâ”€â”€ cleaner.py          # Data normalization
â”‚   â”œâ”€â”€ geo.py              # Geocoding service
â”‚   â”œâ”€â”€ exporter.py         # Export to CSV/XLSX
â”‚   â”œâ”€â”€ utils.py            # Utility functions
â”‚   â”œâ”€â”€ data_cleaner.py     # Advanced data cleaning
â”‚   â””â”€â”€ master_workbook.py  # Master workbook management
â”‚
â”œâ”€â”€ parsers/                  # Site-specific parsers
â”‚   â”œâ”€â”€ specials.py         # Config-driven parser (50+ sites)
â”‚   â””â”€â”€ [site].py           # Site-specific modules
â”‚
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ enable_sites.py     # Enable multiple sites
â”‚   â”œâ”€â”€ enable_one_site.py  # Enable single site
â”‚   â”œâ”€â”€ validate_config.py  # Validate configuration
â”‚   â””â”€â”€ status.py           # Site health dashboard
â”‚
â”œâ”€â”€ tests/                    # Test suite
â”‚   â”œâ”€â”€ test_watcher_integration.py
â”‚   â”œâ”€â”€ test_milestone*.py
â”‚   â””â”€â”€ test_*.py
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ guides/              # User guides
â”‚   â”‚   â”œâ”€â”€ QUICKSTART.md
â”‚   â”‚   â”œâ”€â”€ MIGRATION_GUIDE.md
â”‚   â”‚   â”œâ”€â”€ WATCHER_QUICKSTART.md
â”‚   â”‚   â””â”€â”€ WATCHER_COMPLETE.md
â”‚   â”œâ”€â”€ milestones/          # Milestone completion docs
â”‚   â”‚   â””â”€â”€ MILESTONE_*.md
â”‚   â””â”€â”€ planning/            # Planning documents
â”‚       â”œâ”€â”€ tasks.md
â”‚       â””â”€â”€ planning.md
â”‚
â”œâ”€â”€ exports/                  # Export data
â”‚   â”œâ”€â”€ sites/               # Raw scraper exports
â”‚   â”‚   â”œâ”€â”€ npc/
â”‚   â”‚   â”œâ”€â”€ propertypro/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ cleaned/             # Cleaned & consolidated data
â”‚       â”œâ”€â”€ MASTER_CLEANED_WORKBOOK.xlsx
â”‚       â”œâ”€â”€ metadata.json
â”‚       â”œâ”€â”€ [site]/
â”‚       â”‚   â”œâ”€â”€ [site]_cleaned.csv
â”‚       â”‚   â””â”€â”€ [site]_cleaned.parquet
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ logs/                     # Application logs
    â”œâ”€â”€ scraper.log
    â”œâ”€â”€ geocache.json
    â””â”€â”€ site_metadata.json
```

## ğŸ¯ Core Features

### 1. Web Scraping
- **50+ sites supported** (Nigeria Property Centre, PropertyPro, Jiji, etc.)
- **Config-driven architecture** - Add new sites via YAML
- **Adaptive fetching** - Requests â†’ Playwright fallback
- **Lagos-focused** - Filters for Lagos area properties only
- **Pagination** - Automatic page traversal

### 2. Data Processing
- **Normalization** - Standardizes fields (price, location, property_type)
- **Geocoding** - OpenStreetMap Nominatim integration
- **Deduplication** - Hash-based duplicate removal
- **Validation** - Schema validation & data quality metrics

### 3. Export Watcher Service
- **Monitors** `exports/sites/` for new CSV/XLSX files
- **Cleans** data with intelligent fuzzy matching
- **Consolidates** into `MASTER_CLEANED_WORKBOOK.xlsx`
- **Exports** to CSV and Parquet formats
- **Idempotent** - Safe to run multiple times

### 4. Configuration Management
- **YAML-based** - All sites in `config.yaml`
- **Per-site overrides** - Custom settings per site
- **Environment variables** - Runtime configuration
- **Validation** - Pre-flight config checks

## ğŸ“– Usage

### Basic Scraping

```bash
# Scrape all enabled sites
python main.py

# Enable specific sites only
python scripts/enable_sites.py npc propertypro jiji
python main.py

# Enable one site for testing
python scripts/enable_one_site.py npc
python main.py
```

### Environment Variables

```bash
# Windows
set RP_DEBUG=1              # Enable debug logging
set RP_HEADLESS=0           # Show browser window
set RP_GEOCODE=1            # Enable geocoding
set RP_PAGE_CAP=20          # Max pages per site
set RP_MAX_GEOCODES=200     # Max geocoding requests

# Linux/Mac
export RP_DEBUG=1
export RP_HEADLESS=0
# ... etc
```

### Export Processing

```bash
# Process all exports once
python watcher.py --once

# Continuous monitoring (daemon mode)
python watcher.py --watch

# Preview without writing
python watcher.py --dry-run --once

# Reset and reprocess all
python watcher.py --reset-state
python watcher.py --once
```

### Validation & Monitoring

```bash
# Validate configuration
python scripts/validate_config.py

# Check site health
python scripts/status.py

# Run tests
python tests/test_watcher_integration.py
```

## ğŸ”§ Configuration

### config.yaml Structure

```yaml
global_settings:
  geocoding:
    enabled: true
    max_per_run: 120
  pagination:
    max_pages: 30
    scroll_steps: 12
  retry:
    network_retry_seconds: 180
    retry_on_zero_results: true
  export:
    formats: ["csv", "xlsx"]
  browser:
    headless: true
    block_images: true

sites:
  npc:
    name: "Nigeria Property Centre"
    url: "https://nigeriapropertycentre.com"
    enabled: true
    parser: specials
    selectors:
      card: "div.listing"
      title: "h2.title"
      price: ".price"
      location: ".location"
    pagination:
      next_selectors: ["a.next", "a[rel='next']"]
      page_param: "page"
    overrides:
      network_retry_seconds: 300
      max_pages: 50
```

## ğŸ“Š Data Schema

All listings normalized to canonical schema:

```python
{
  'title': str,
  'price': str,
  'location': str,
  'property_type': str,
  'bedrooms': int,
  'bathrooms': int,
  'land_size': str,
  'description': str,
  'agent_name': str,
  'images': List[str],
  'listing_url': str,
  'coordinates': Dict[str, float],
  'source': str,
  'scrape_timestamp': str,
  'hash': str,
  # ... 27 total fields
}
```

## ğŸ§ª Testing

```bash
# Run all integration tests
cd tests
python test_watcher_integration.py      # Watcher service tests
python test_milestone4_5.py             # Config system tests
python test_site_specific.py            # Site config tests

# Test results: 57/58 tests passing (98.3%)
```

## ğŸ“š Documentation

**Getting Started:**
- **[QUICKSTART.md](docs/guides/QUICKSTART.md)** - Quick start guide for scraper
- **[WATCHER_QUICKSTART.md](docs/guides/WATCHER_QUICKSTART.md)** - Quick start for watcher service
- **[API_QUICKSTART.md](docs/guides/API_QUICKSTART.md)** - API quick start

**Integration Guides:**
- **[FRONTEND_INTEGRATION.md](docs/guides/FRONTEND_INTEGRATION.md)** - Complete Next.js integration guide
- **[MIGRATION_GUIDE.md](docs/guides/MIGRATION_GUIDE.md)** - Migration to config-driven system

**Architecture:**
- **[CLAUDE.md](CLAUDE.md)** - AI assistant context & project overview
- **[STRUCTURE.md](docs/STRUCTURE.md)** - Detailed project architecture
- **[FILE_STRUCTURE.md](docs/FILE_STRUCTURE.md)** - Clean file organization reference
- **[COMPATIBILITY.md](docs/COMPATIBILITY.md)** - Firebase deployment compatibility

## ğŸš€ Deployment

### FREE Deployment Options (No Cost!) ğŸ’°

**ğŸ† RECOMMENDED**: See **[FREE_DEPLOYMENT.md](FREE_DEPLOYMENT.md)** - Complete guide to FREE deployment

**Top FREE Options**:

1. **â­ GitHub Actions** (Best for most users)
   - âœ… $0/month - Completely FREE
   - âœ… 2000 minutes/month free
   - âœ… No credit card required
   - âœ… Scheduled scraping (cron)
   - âœ… 15-minute setup
   - **Perfect for**: Daily/weekly scraping

2. **ğŸŒ Oracle Cloud Always Free**
   - âœ… $0/month - FREE forever
   - âœ… 1-4 CPUs, 6-24GB RAM free
   - âœ… Can run 24/7
   - âš ï¸ Requires credit card verification (never charges)
   - **Perfect for**: 24/7 availability or API hosting

3. **ğŸ’» Local Machine**
   - âœ… $0/month - Completely FREE
   - âœ… Full control
   - âœ… 5-minute setup
   - âŒ Computer must stay on
   - **Perfect for**: Testing and development

**See [FREE_DEPLOYMENT.md](FREE_DEPLOYMENT.md) for complete setup guides for all FREE options!**

---

### Firebase Deployment (Paid, ~$1-5/month)

**Quick Start**: See **[FIREBASE_QUICKSTART.md](FIREBASE_QUICKSTART.md)** - Fast setup guide

**Complete Guide**: See **[docs/FIREBASE_DEPLOYMENT.md](docs/FIREBASE_DEPLOYMENT.md)** - Step-by-step deployment walkthrough

**What you get**:
- âœ… **Serverless** - No server management required
- âœ… **Cloud Functions** - Automated scheduled scraping
- âœ… **Cloud Storage** - Unlimited data storage with CDN
- âœ… **Scalable** - Auto-scales based on demand
- âœ… **Cost**: ~$1-5/month (pay-as-you-go)

**When to use Firebase**:
- Need enterprise-grade reliability
- Want global CDN for data access
- Integrating with Firebase-based frontend
- Need more than 2000 minutes/month

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `python tests/test_*.py`
5. Update documentation
6. Submit a pull request

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- Built with: Python 3.8+, Playwright, BeautifulSoup4, Pandas, OpenPyXL
- Geocoding: OpenStreetMap Nominatim
- AI Assistance: Claude Code (Anthropic)

## ğŸ”— Links

- **GitHub**: [Repository Link]
- **Documentation**: [docs/](docs/)
- **Issues**: [GitHub Issues]

---

**Status**: âœ… Production Ready | **Version**: 1.0 | **Last Updated**: 2025-10-05
